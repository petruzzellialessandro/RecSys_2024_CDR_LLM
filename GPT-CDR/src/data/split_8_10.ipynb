{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_dir_path(curr_working_dir, no_folders_above):\n",
    "    dir_path = curr_working_dir\n",
    "    for i in range(no_folders_above):\n",
    "        dir_path = os.path.dirname(dir_path)\n",
    "    print(f\"Initial directory: {curr_working_dir}\\n\"\n",
    "          f\"Root directory: {dir_path}.\"\n",
    "          )\n",
    "    return dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data_by_column(df, column_to_keep, column_to_group_data):\n",
    "    \"\"\"Method to group the data within a dataframe given two columns' headers.\"\"\"\n",
    "    temp_df = df.groupby(column_to_keep)[column_to_group_data].count()\n",
    "    temp_df = pd.DataFrame({'user_id': temp_df.index, 'no_reviews_user': temp_df.values})\n",
    "    return temp_df\n",
    "\n",
    "def cut_at_x_y(x_val, y_val, df, target_column):\n",
    "    \"\"\"Method used to filter out data for a specific Cut@x_y scenario\"\"\"\n",
    "    print(f\">>>>> Cut@{x_val}_{y_val} Scenario <<<<<\\n\"\n",
    "          f\"=============================\")\n",
    "    tmp_df = df[(df[target_column] >= x_val) & (df[target_column] <= y_val)]\n",
    "    \n",
    "    print(f\"We have a total of {len(tmp_df)} users split as follows:\")\n",
    "    for i in range(x_val,y_val+1):\n",
    "        print(f\"- {count_users_by_no_review(tmp_df, i)} users with {i} reviews\")\n",
    "    print(\"=============================\")\n",
    "    \n",
    "    return tmp_df\n",
    "\n",
    "def count_users_by_no_review(df, review_no):\n",
    "    return df[df['no_reviews_user'] == review_no]['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_SUBSET = ['user_id', 'item_id', 'rating', 'timestamp', 'title', 'brand', 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_user_data_from_dataframe(main_df, user_list, path_store_data):\n",
    "    \"\"\"Method to extract rows from a dataframe given a list of valid users\"\"\"\n",
    "    \n",
    "    # Filter dataframe\n",
    "    tmp_df = main_df[main_df['user_id'].isin(user_list)]\n",
    "    print(f\"The current dataframe contains {len(tmp_df)} rows!\\n\"\n",
    "          f\"It contains {tmp_df['user_id'].nunique()} users!\\n\"\n",
    "          f\"It contains {tmp_df['item_id'].nunique()} items!\\n\"\n",
    "          f\"Storing dataframe...\")\n",
    "    \n",
    "    df_cpy = tmp_df.copy()\n",
    "    df_cpy.drop_duplicates(inplace=True, subset=COLS_SUBSET)\n",
    "\n",
    "    if len(tmp_df) != len(df_cpy):\n",
    "        print(\"Duplicates have been found!\")\n",
    "    \n",
    "    print(f\"The current dataframe contains {len(df_cpy)} rows!\\n\"\n",
    "          f\"It contains {df_cpy['user_id'].nunique()} users!\\n\"\n",
    "          f\"It contains {df_cpy['item_id'].nunique()} items!\\n\")\n",
    "    # Store the new dataframe\n",
    "    file_dir_path = path_store_data \n",
    "    df_cpy.drop(df_cpy.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    df_cpy.to_csv(file_dir_path, index=False)\n",
    "    print(f\"The dataframe has been stored!\")\n",
    "    print(\"=================================================\")\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial directory: d:\\CrossDomain_RecSys_LLM-main\\src\\data\n",
      "Root directory: d:\\CrossDomain_RecSys_LLM-main.\n"
     ]
    }
   ],
   "source": [
    "COLUMNS_TYPES =  {\n",
    "        'user_id': 'string',\n",
    "        'item_id': 'string',\n",
    "        'rating': 'int',\n",
    "        'timestamp': 'string',\n",
    "        'title': 'string',\n",
    "        'brand': 'string',\n",
    "        'category': 'string'\n",
    "    }\n",
    "\n",
    "ROOT_DIR = get_root_dir_path(os.getcwd(), 2)\n",
    "\n",
    "# ==================== DATA DIRECTORIES ==================== #\n",
    "DATA_DIR = ROOT_DIR + '/data/processed/'\n",
    "\n",
    "BOOKS35_DIR = DATA_DIR + '/Books3_5/'\n",
    "CDS35_DIR = DATA_DIR + '/CDs3_5/'\n",
    "MOVIES35_DIR = DATA_DIR + '/Movies3_5/'\n",
    "\n",
    "EXTRA_DATA_DIR = ROOT_DIR + '/data/processed/extra_cut/'\n",
    "\n",
    "EXTRA_BOOKS_DIR = EXTRA_DATA_DIR + '/Books1/'\n",
    "EXTRA_CDS_DIR = EXTRA_DATA_DIR + '/CDs1/'\n",
    "EXTRA_MOVIES_DIR = EXTRA_DATA_DIR + '/Movies1/'\n",
    "RAW_DIR = ROOT_DIR + '/src/data/raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_5_10__BOOKS = pd.read_csv(BOOKS35_DIR + \"cds_5_10.csv\")\n",
    "movies_5_10__BOOKS = pd.read_csv(BOOKS35_DIR + \"movies_5_10.csv\")\n",
    "'''filtered_books = pd.read_csv(RAW_DIR + \"/filtered_books.csv\")\n",
    "filtered_movies = pd.read_csv(RAW_DIR + \"/filtered_movies.csv\")\n",
    "filtered_cds = pd.read_csv(RAW_DIR + \"/filtered_cds.csv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "'''filtered_books_grouped = group_data_by_column(filtered_books, 'user_id', 'item_id')\n",
    "filtered_movies_grouped = group_data_by_column(filtered_movies, 'user_id', 'item_id')\n",
    "filtered_cds_grouped = group_data_by_column(filtered_cds, 'user_id', 'item_id')'''\n",
    "\n",
    "\n",
    "'''# 5_10 base + 10_20 10_30\n",
    "\n",
    "books_5_10 = cut_at_x_y(5, 10, filtered_books_grouped, 'no_reviews_user')\n",
    "movies_5_10 = cut_at_x_y(5, 10, filtered_movies_grouped, 'no_reviews_user')\n",
    "cds_5_10 = cut_at_x_y(5, 10, filtered_cds_grouped, 'no_reviews_user')\n",
    "\n",
    "#10_20 e 10_30 target\n",
    "\n",
    "books_10_20 = cut_at_x_y(10, 20, filtered_books_grouped, 'no_reviews_user')\n",
    "books_10_30 = cut_at_x_y(10, 30, filtered_books_grouped, 'no_reviews_user')\n",
    "movies_10_20 = cut_at_x_y(10, 20, filtered_movies_grouped, 'no_reviews_user')\n",
    "movies_10_30 = cut_at_x_y(10, 30, filtered_movies_grouped, 'no_reviews_user')\n",
    "cds_10_20 = cut_at_x_y(10, 20, filtered_cds_grouped, 'no_reviews_user')\n",
    "cds_10_30 = cut_at_x_y(10, 30, filtered_cds_grouped, 'no_reviews_user')\n",
    "\n",
    "#5_20 e 5_30 base\n",
    "\n",
    "books_5_20 = cut_at_x_y(5, 20, filtered_books_grouped, 'no_reviews_user')\n",
    "books_5_30 = cut_at_x_y(5, 30, filtered_books_grouped, 'no_reviews_user')\n",
    "movies_5_20 = cut_at_x_y(5, 20, filtered_movies_grouped, 'no_reviews_user')\n",
    "movies_5_30 = cut_at_x_y(5, 30, filtered_movies_grouped, 'no_reviews_user')\n",
    "cds_5_20 = cut_at_x_y(5, 20, filtered_cds_grouped, 'no_reviews_user')\n",
    "cds_5_30 = cut_at_x_y(5, 30, filtered_cds_grouped, 'no_reviews_user')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Cut@5_20 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 5657 users split as follows:\n",
      "- 847 users with 5 reviews\n",
      "- 711 users with 6 reviews\n",
      "- 600 users with 7 reviews\n",
      "- 533 users with 8 reviews\n",
      "- 420 users with 9 reviews\n",
      "- 377 users with 10 reviews\n",
      "- 321 users with 11 reviews\n",
      "- 301 users with 12 reviews\n",
      "- 259 users with 13 reviews\n",
      "- 244 users with 14 reviews\n",
      "- 212 users with 15 reviews\n",
      "- 190 users with 16 reviews\n",
      "- 192 users with 17 reviews\n",
      "- 156 users with 18 reviews\n",
      "- 175 users with 19 reviews\n",
      "- 119 users with 20 reviews\n",
      "=============================\n",
      ">>>>> Cut@5_30 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 6620 users split as follows:\n",
      "- 847 users with 5 reviews\n",
      "- 711 users with 6 reviews\n",
      "- 600 users with 7 reviews\n",
      "- 533 users with 8 reviews\n",
      "- 420 users with 9 reviews\n",
      "- 377 users with 10 reviews\n",
      "- 321 users with 11 reviews\n",
      "- 301 users with 12 reviews\n",
      "- 259 users with 13 reviews\n",
      "- 244 users with 14 reviews\n",
      "- 212 users with 15 reviews\n",
      "- 190 users with 16 reviews\n",
      "- 192 users with 17 reviews\n",
      "- 156 users with 18 reviews\n",
      "- 175 users with 19 reviews\n",
      "- 119 users with 20 reviews\n",
      "- 105 users with 21 reviews\n",
      "- 123 users with 22 reviews\n",
      "- 121 users with 23 reviews\n",
      "- 99 users with 24 reviews\n",
      "- 101 users with 25 reviews\n",
      "- 96 users with 26 reviews\n",
      "- 93 users with 27 reviews\n",
      "- 73 users with 28 reviews\n",
      "- 87 users with 29 reviews\n",
      "- 65 users with 30 reviews\n",
      "=============================\n",
      ">>>>> Cut@5_20 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 5494 users split as follows:\n",
      "- 826 users with 5 reviews\n",
      "- 742 users with 6 reviews\n",
      "- 612 users with 7 reviews\n",
      "- 486 users with 8 reviews\n",
      "- 425 users with 9 reviews\n",
      "- 389 users with 10 reviews\n",
      "- 325 users with 11 reviews\n",
      "- 278 users with 12 reviews\n",
      "- 252 users with 13 reviews\n",
      "- 211 users with 14 reviews\n",
      "- 215 users with 15 reviews\n",
      "- 195 users with 16 reviews\n",
      "- 145 users with 17 reviews\n",
      "- 144 users with 18 reviews\n",
      "- 123 users with 19 reviews\n",
      "- 126 users with 20 reviews\n",
      "=============================\n",
      ">>>>> Cut@5_30 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 6278 users split as follows:\n",
      "- 826 users with 5 reviews\n",
      "- 742 users with 6 reviews\n",
      "- 612 users with 7 reviews\n",
      "- 486 users with 8 reviews\n",
      "- 425 users with 9 reviews\n",
      "- 389 users with 10 reviews\n",
      "- 325 users with 11 reviews\n",
      "- 278 users with 12 reviews\n",
      "- 252 users with 13 reviews\n",
      "- 211 users with 14 reviews\n",
      "- 215 users with 15 reviews\n",
      "- 195 users with 16 reviews\n",
      "- 145 users with 17 reviews\n",
      "- 144 users with 18 reviews\n",
      "- 123 users with 19 reviews\n",
      "- 126 users with 20 reviews\n",
      "- 105 users with 21 reviews\n",
      "- 87 users with 22 reviews\n",
      "- 117 users with 23 reviews\n",
      "- 68 users with 24 reviews\n",
      "- 69 users with 25 reviews\n",
      "- 78 users with 26 reviews\n",
      "- 81 users with 27 reviews\n",
      "- 63 users with 28 reviews\n",
      "- 49 users with 29 reviews\n",
      "- 67 users with 30 reviews\n",
      "=============================\n",
      ">>>>> Cut@5_20 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 6112 users split as follows:\n",
      "- 1010 users with 5 reviews\n",
      "- 880 users with 6 reviews\n",
      "- 764 users with 7 reviews\n",
      "- 547 users with 8 reviews\n",
      "- 470 users with 9 reviews\n",
      "- 440 users with 10 reviews\n",
      "- 317 users with 11 reviews\n",
      "- 289 users with 12 reviews\n",
      "- 240 users with 13 reviews\n",
      "- 214 users with 14 reviews\n",
      "- 220 users with 15 reviews\n",
      "- 205 users with 16 reviews\n",
      "- 150 users with 17 reviews\n",
      "- 129 users with 18 reviews\n",
      "- 112 users with 19 reviews\n",
      "- 125 users with 20 reviews\n",
      "=============================\n",
      ">>>>> Cut@5_30 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 6906 users split as follows:\n",
      "- 1010 users with 5 reviews\n",
      "- 880 users with 6 reviews\n",
      "- 764 users with 7 reviews\n",
      "- 547 users with 8 reviews\n",
      "- 470 users with 9 reviews\n",
      "- 440 users with 10 reviews\n",
      "- 317 users with 11 reviews\n",
      "- 289 users with 12 reviews\n",
      "- 240 users with 13 reviews\n",
      "- 214 users with 14 reviews\n",
      "- 220 users with 15 reviews\n",
      "- 205 users with 16 reviews\n",
      "- 150 users with 17 reviews\n",
      "- 129 users with 18 reviews\n",
      "- 112 users with 19 reviews\n",
      "- 125 users with 20 reviews\n",
      "- 109 users with 21 reviews\n",
      "- 105 users with 22 reviews\n",
      "- 83 users with 23 reviews\n",
      "- 95 users with 24 reviews\n",
      "- 69 users with 25 reviews\n",
      "- 72 users with 26 reviews\n",
      "- 77 users with 27 reviews\n",
      "- 64 users with 28 reviews\n",
      "- 46 users with 29 reviews\n",
      "- 74 users with 30 reviews\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "cds__BOOKS_grouped = group_data_by_column(cds_5_10__BOOKS, 'user_id', 'item_id')\n",
    "movies__BOOKS_grouped = group_data_by_column(movies_5_10__BOOKS, 'user_id', 'item_id')\n",
    "\n",
    "\n",
    "books_5_10__MOVIES = pd.read_csv(MOVIES35_DIR + \"books5_10.csv\")\n",
    "\n",
    "cds_5_10__BOOKS_8_10 = cut_at_x_y(8, 10, cds__BOOKS_grouped, 'no_reviews_user')\n",
    "movies_5_10__BOOKS_8_10 = cut_at_x_y(8, 10, movies__BOOKS_grouped, 'no_reviews_user')\n",
    "\n",
    "cds_5_10__BOOKS_10_10 = cut_at_x_y(10, 10, cds__BOOKS_grouped, 'no_reviews_user')\n",
    "movies_5_10__BOOKS_10_10 = cut_at_x_y(10, 10, movies__BOOKS_grouped, 'no_reviews_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing\n",
    "'''#base domain normali\n",
    "path3 = EXTRA_MOVIES_DIR + 'movies_5_10.csv'\n",
    "path4 = EXTRA_BOOKS_DIR + 'books_5_10.csv'\n",
    "path5 = EXTRA_CDS_DIR + 'cds_5_10.csv'\n",
    "\n",
    "#base domain\n",
    "path6 = EXTRA_MOVIES_DIR + 'movies_5_20.csv'\n",
    "path7 = EXTRA_MOVIES_DIR + 'movies_5_30.csv'\n",
    "path8 = EXTRA_BOOKS_DIR + 'books_5_20.csv'\n",
    "path9 = EXTRA_BOOKS_DIR + 'books_5_30.csv'\n",
    "path10 = EXTRA_CDS_DIR + 'cds_5_20.csv'\n",
    "path11 = EXTRA_CDS_DIR + 'cds_5_30.csv'\n",
    "\n",
    "path24 = EXTRA_CDS_DIR + 'movies_5_20.csv'\n",
    "path25 = EXTRA_CDS_DIR + 'movies_5_30.csv'\n",
    "path26 = EXTRA_CDS_DIR + 'books_5_20.csv'\n",
    "path27 = EXTRA_CDS_DIR + 'books_5_30.csv'\n",
    "path28 = EXTRA_BOOKS_DIR + 'cds_5_20.csv'\n",
    "path29 = EXTRA_BOOKS_DIR + 'cds_5_30.csv'\n",
    "\n",
    "#base domain joinati\n",
    "path12 = EXTRA_MOVIES_DIR + 'movies_5_10_1.csv' # books_10_20\n",
    "path13 = EXTRA_MOVIES_DIR + 'movies_5_10_2.csv' # books_10_30\n",
    "path14 = EXTRA_CDS_DIR + 'cds_5_10_1.csv' # books_10_20\n",
    "path15 = EXTRA_CDS_DIR + 'cds_5_10_2.csv' # books_10_30\n",
    "path16 = EXTRA_BOOKS_DIR + 'books_5_10_1.csv' #  movies_10_20\n",
    "path17 = EXTRA_BOOKS_DIR + 'books_5_10_2.csv' # movies_10_30\n",
    "path18 = EXTRA_CDS_DIR + 'cds_5_10_3.csv' # movies_10_20\n",
    "path19 = EXTRA_CDS_DIR + 'cds_5_10_4.csv' # movies_10_30\n",
    "path20 = EXTRA_MOVIES_DIR + 'movies_5_10_3.csv' # cds_10_20\n",
    "path21 = EXTRA_MOVIES_DIR + 'movies_5_10_4.csv' # cds_10_30\n",
    "path22 = EXTRA_BOOKS_DIR + 'books_5_10_3.csv' #  cds_10_20\n",
    "path23 = EXTRA_BOOKS_DIR + 'books_5_10_4.csv' # cds_10_30\n",
    "\n",
    "#base domain joinati 10_20 10_30\n",
    "path12 = EXTRA_MOVIES_DIR + 'movies_5_20_1.csv' # books_10_20\n",
    "path13 = EXTRA_MOVIES_DIR + 'movies_5_20_2.csv' # books_10_30\n",
    "path14 = EXTRA_CDS_DIR + 'cds_5_20_1.csv' # books_10_20\n",
    "path15 = EXTRA_CDS_DIR + 'cds_5_20_2.csv' # books_10_30\n",
    "path16 = EXTRA_BOOKS_DIR + 'books_5_20_1.csv' #  movies_10_20\n",
    "path17 = EXTRA_BOOKS_DIR + 'books_5_20_2.csv' # movies_10_30\n",
    "path18 = EXTRA_CDS_DIR + 'cds_5_20_3.csv' # movies_10_20\n",
    "path19 = EXTRA_CDS_DIR + 'cds_5_20_4.csv' # movies_10_30\n",
    "path20 = EXTRA_MOVIES_DIR + 'movies_5_20_3.csv' # cds_10_20\n",
    "path21 = EXTRA_MOVIES_DIR + 'movies_5_20_4.csv' # cds_10_30\n",
    "path22 = EXTRA_BOOKS_DIR + 'books_5_20_3.csv' #  cds_10_20\n",
    "path23 = EXTRA_BOOKS_DIR + 'books_5_20_4.csv' # cds_10_30\n",
    "\n",
    "movies_510 = retrieve_user_data_from_dataframe(filtered_movies, movies_5_10['user_id'], path3)\n",
    "books_510 = retrieve_user_data_from_dataframe(filtered_books, books_5_10['user_id'], path4)\n",
    "cds_510 = retrieve_user_data_from_dataframe(filtered_cds, cds_5_10['user_id'], path5)\n",
    "\n",
    "\n",
    "movies_520 = retrieve_user_data_from_dataframe(filtered_movies, movies_5_20['user_id'], path6)\n",
    "movies_530 = retrieve_user_data_from_dataframe(filtered_movies, movies_5_30['user_id'], path7)\n",
    "books_520 = retrieve_user_data_from_dataframe(filtered_books, books_5_20['user_id'], path8)\n",
    "books_530 = retrieve_user_data_from_dataframe(filtered_books, books_5_30['user_id'], path9)\n",
    "cds_520 = retrieve_user_data_from_dataframe(filtered_cds, cds_5_20['user_id'], path10)\n",
    "cds_530 = retrieve_user_data_from_dataframe(filtered_cds, cds_5_30['user_id'], path11)\n",
    "movies_520 = retrieve_user_data_from_dataframe(filtered_movies, movies_5_20['user_id'], path24)\n",
    "movies_530 = retrieve_user_data_from_dataframe(filtered_movies, movies_5_30['user_id'], path25)\n",
    "books_520 = retrieve_user_data_from_dataframe(filtered_books, books_5_20['user_id'], path26)\n",
    "books_530 = retrieve_user_data_from_dataframe(filtered_books, books_5_30['user_id'], path27)\n",
    "cds_520 = retrieve_user_data_from_dataframe(filtered_cds, cds_5_20['user_id'], path28)\n",
    "cds_530 = retrieve_user_data_from_dataframe(filtered_cds, cds_5_30['user_id'], path29)\n",
    "\n",
    "#base domain 5_10\n",
    "\n",
    "movies_5_10 = pd.read_csv(EXTRA_MOVIES_DIR + \"movies_5_10.csv\")\n",
    "cds_5_10 = pd.read_csv(EXTRA_CDS_DIR + \"cds_5_10.csv\")\n",
    "books_5_10 = pd.read_csv(EXTRA_BOOKS_DIR + \"books_5_10.csv\")\n",
    "\n",
    "#base domain 5_20 5_30\n",
    "\n",
    "movies_5_20 = pd.read_csv(EXTRA_MOVIES_DIR + \"movies_5_20.csv\")\n",
    "movies_5_30 = pd.read_csv(EXTRA_MOVIES_DIR + \"movies_5_30.csv\")\n",
    "books_5_20 = pd.read_csv(EXTRA_BOOKS_DIR + \"books_5_20.csv\")\n",
    "books_5_30 = pd.read_csv(EXTRA_BOOKS_DIR + \"books_5_30.csv\")\n",
    "cds_5_20 = pd.read_csv(EXTRA_CDS_DIR + \"cds_5_20.csv\")\n",
    "cds_5_30 = pd.read_csv(EXTRA_CDS_DIR + \"cds_5_30.csv\")\n",
    "\n",
    "movies_10_20 = pd.read_csv(EXTRA_BOOKS_DIR + \"movies_10_20.csv\")\n",
    "movies_10_30 = pd.read_csv(EXTRA_BOOKS_DIR + \"movies_10_30.csv\")\n",
    "books_10_20 = pd.read_csv(EXTRA_MOVIES_DIR + \"books_10_20.csv\")\n",
    "books_10_30 = pd.read_csv(EXTRA_MOVIES_DIR + \"books_10_30.csv\")\n",
    "cds_10_20 = pd.read_csv(EXTRA_BOOKS_DIR + \"cds_10_20.csv\")\n",
    "cds_10_30 = pd.read_csv(EXTRA_BOOKS_DIR + \"cds_10_30.csv\")\n",
    "\n",
    "#target domain 10_20 10_30 con base 5_10\n",
    "movies_510_1 = retrieve_user_data_from_dataframe(movies_5_10, books_1020['user_id'], path12)\n",
    "movies_510_2 = retrieve_user_data_from_dataframe(movies_5_10, books_1030['user_id'], path13)\n",
    "cds_510_1 = retrieve_user_data_from_dataframe(cds_5_10, books_1020['user_id'], path14)\n",
    "cds_510_2 = retrieve_user_data_from_dataframe(cds_5_10, books_1030['user_id'], path15)\n",
    "books_510_1 = retrieve_user_data_from_dataframe(books_5_10, movies_1020['user_id'], path16)\n",
    "books_510_2 = retrieve_user_data_from_dataframe(books_5_10, movies_1030['user_id'], path17)\n",
    "cds_510_3 = retrieve_user_data_from_dataframe(cds_5_10, movies_1020['user_id'], path18)\n",
    "cds_510_4 = retrieve_user_data_from_dataframe(cds_5_10, movies_1030['user_id'], path19)\n",
    "movies_510_3 = retrieve_user_data_from_dataframe(movies_5_10, cds_1020['user_id'], path20)\n",
    "movies_510_4 = retrieve_user_data_from_dataframe(movies_5_10, cds_1030['user_id'], path21)\n",
    "books_510_3 = retrieve_user_data_from_dataframe(books_5_10, cds_1020['user_id'], path22)\n",
    "books_510_4 = retrieve_user_data_from_dataframe(books_5_10, cds_1030['user_id'], path23)\n",
    "\n",
    "#target domain 10_20 10_30 con base 10_20 10_30\n",
    "\n",
    "movies_520_1 = retrieve_user_data_from_dataframe(movies_5_20, books_10_20['user_id'], path12)\n",
    "movies_520_2 = retrieve_user_data_from_dataframe(movies_5_20, books_10_30['user_id'], path13)\n",
    "cds_520_1 = retrieve_user_data_from_dataframe(cds_5_20, books_10_20['user_id'], path14)\n",
    "cds_520_2 = retrieve_user_data_from_dataframe(cds_5_20, books_10_30['user_id'], path15)\n",
    "books_520_1 = retrieve_user_data_from_dataframe(books_5_20, movies_10_20['user_id'], path16)\n",
    "books_520_2 = retrieve_user_data_from_dataframe(books_5_20, movies_10_30['user_id'], path17)\n",
    "cds_520_3 = retrieve_user_data_from_dataframe(cds_5_20, movies_10_20['user_id'], path18)\n",
    "cds_520_4 = retrieve_user_data_from_dataframe(cds_5_20, movies_10_30['user_id'], path19)\n",
    "movies_520_3 = retrieve_user_data_from_dataframe(movies_5_20, cds_10_20['user_id'], path20)\n",
    "movies_520_4 = retrieve_user_data_from_dataframe(movies_5_20, cds_10_30['user_id'], path21)\n",
    "books_520_3 = retrieve_user_data_from_dataframe(books_5_20, cds_10_20['user_id'], path22)\n",
    "books_520_4 = retrieve_user_data_from_dataframe(books_5_20, cds_10_30['user_id'], path23)\n",
    "\n",
    "path12 = EXTRA_MOVIES_DIR + 'movies_5_30_1.csv' # books_10_20\n",
    "path13 = EXTRA_MOVIES_DIR + 'movies_5_30_2.csv' # books_10_30\n",
    "path14 = EXTRA_CDS_DIR + 'cds_5_30_1.csv' # books_10_20\n",
    "path15 = EXTRA_CDS_DIR + 'cds_5_30_2.csv' # books_10_30\n",
    "path16 = EXTRA_BOOKS_DIR + 'books_5_30_1.csv' #  movies_10_20\n",
    "path17 = EXTRA_BOOKS_DIR + 'books_5_30_2.csv' # movies_10_30\n",
    "path18 = EXTRA_CDS_DIR + 'cds_5_30_3.csv' # movies_10_20\n",
    "path19 = EXTRA_CDS_DIR + 'cds_5_30_4.csv' # movies_10_30\n",
    "path20 = EXTRA_MOVIES_DIR + 'movies_5_30_3.csv' # cds_10_20\n",
    "path21 = EXTRA_MOVIES_DIR + 'movies_5_30_4.csv' # cds_10_30\n",
    "path22 = EXTRA_BOOKS_DIR + 'books_5_30_3.csv' #  cds_10_20\n",
    "path23 = EXTRA_BOOKS_DIR + 'books_5_30_4.csv' # cds_10_30\n",
    "\n",
    "movies_530_1 = retrieve_user_data_from_dataframe(movies_5_30, books_10_20['user_id'], path12)\n",
    "movies_530_2 = retrieve_user_data_from_dataframe(movies_5_30, books_10_30['user_id'], path13)\n",
    "cds_530_1 = retrieve_user_data_from_dataframe(cds_5_30, books_10_20['user_id'], path14)\n",
    "cds_530_2 = retrieve_user_data_from_dataframe(cds_5_30, books_10_30['user_id'], path15)\n",
    "books_530_1 = retrieve_user_data_from_dataframe(books_5_30, movies_10_20['user_id'], path16)\n",
    "books_530_2 = retrieve_user_data_from_dataframe(books_5_30, movies_10_30['user_id'], path17)\n",
    "cds_530_3 = retrieve_user_data_from_dataframe(cds_5_30, movies_10_20['user_id'], path18)\n",
    "cds_530_4 = retrieve_user_data_from_dataframe(cds_5_30, movies_10_30['user_id'], path19)\n",
    "movies_530_3 = retrieve_user_data_from_dataframe(movies_5_30, cds_10_20['user_id'], path20)\n",
    "movies_530_4 = retrieve_user_data_from_dataframe(movies_5_30, cds_10_30['user_id'], path21)\n",
    "books_530_3 = retrieve_user_data_from_dataframe(books_5_30, cds_10_20['user_id'], path22)\n",
    "books_530_4 = retrieve_user_data_from_dataframe(books_5_30, cds_10_30['user_id'], path23)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataframe contains 53869 rows!\n",
      "It contains 5494 users!\n",
      "It contains 16237 items!\n",
      "Storing dataframe...\n",
      "Duplicates have been found!\n",
      "The current dataframe contains 43057 rows!\n",
      "It contains 5494 users!\n",
      "It contains 16237 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 73446 rows!\n",
      "It contains 6278 users!\n",
      "It contains 19045 items!\n",
      "Storing dataframe...\n",
      "Duplicates have been found!\n",
      "The current dataframe contains 58560 rows!\n",
      "It contains 6278 users!\n",
      "It contains 19045 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 56438 rows!\n",
      "It contains 5657 users!\n",
      "It contains 41402 items!\n",
      "Storing dataframe...\n",
      "Duplicates have been found!\n",
      "The current dataframe contains 56434 rows!\n",
      "It contains 5657 users!\n",
      "It contains 41402 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 80557 rows!\n",
      "It contains 6620 users!\n",
      "It contains 55394 items!\n",
      "Storing dataframe...\n",
      "Duplicates have been found!\n",
      "The current dataframe contains 80551 rows!\n",
      "It contains 6620 users!\n",
      "It contains 55394 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 57835 rows!\n",
      "It contains 6112 users!\n",
      "It contains 24699 items!\n",
      "Storing dataframe...\n",
      "Duplicates have been found!\n",
      "The current dataframe contains 45716 rows!\n",
      "It contains 6112 users!\n",
      "It contains 24699 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 77645 rows!\n",
      "It contains 6906 users!\n",
      "It contains 30017 items!\n",
      "Storing dataframe...\n",
      "Duplicates have been found!\n",
      "The current dataframe contains 61235 rows!\n",
      "It contains 6906 users!\n",
      "It contains 30017 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 10686 rows!\n",
      "It contains 1373 users!\n",
      "It contains 6725 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 10686 rows!\n",
      "It contains 1373 users!\n",
      "It contains 6725 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 14573 rows!\n",
      "It contains 1853 users!\n",
      "It contains 8317 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 14573 rows!\n",
      "It contains 1853 users!\n",
      "It contains 8317 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 11139 rows!\n",
      "It contains 1487 users!\n",
      "It contains 8716 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 11139 rows!\n",
      "It contains 1487 users!\n",
      "It contains 8716 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 14972 rows!\n",
      "It contains 1998 users!\n",
      "It contains 11072 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 14972 rows!\n",
      "It contains 1998 users!\n",
      "It contains 11072 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 12855 rows!\n",
      "It contains 1265 users!\n",
      "It contains 11345 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 12855 rows!\n",
      "It contains 1265 users!\n",
      "It contains 11345 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 16682 rows!\n",
      "It contains 1621 users!\n",
      "It contains 14289 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 16682 rows!\n",
      "It contains 1621 users!\n",
      "It contains 14289 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 10716 rows!\n",
      "It contains 1401 users!\n",
      "It contains 8315 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 10716 rows!\n",
      "It contains 1401 users!\n",
      "It contains 8315 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 13945 rows!\n",
      "It contains 1811 users!\n",
      "It contains 10148 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 13945 rows!\n",
      "It contains 1811 users!\n",
      "It contains 10148 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 10305 rows!\n",
      "It contains 1292 users!\n",
      "It contains 6449 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 10305 rows!\n",
      "It contains 1292 users!\n",
      "It contains 6449 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 13541 rows!\n",
      "It contains 1687 users!\n",
      "It contains 7693 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 13541 rows!\n",
      "It contains 1687 users!\n",
      "It contains 7693 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 12908 rows!\n",
      "It contains 1268 users!\n",
      "It contains 11366 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 12908 rows!\n",
      "It contains 1268 users!\n",
      "It contains 11366 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 16796 rows!\n",
      "It contains 1649 users!\n",
      "It contains 14297 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 16796 rows!\n",
      "It contains 1649 users!\n",
      "It contains 14297 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 14579 rows!\n",
      "It contains 1572 users!\n",
      "It contains 8375 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 14579 rows!\n",
      "It contains 1572 users!\n",
      "It contains 8375 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 20289 rows!\n",
      "It contains 2145 users!\n",
      "It contains 10366 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 20289 rows!\n",
      "It contains 2145 users!\n",
      "It contains 10366 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 14762 rows!\n",
      "It contains 1674 users!\n",
      "It contains 10992 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 14762 rows!\n",
      "It contains 1674 users!\n",
      "It contains 10992 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 20294 rows!\n",
      "It contains 2269 users!\n",
      "It contains 14134 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 20294 rows!\n",
      "It contains 2269 users!\n",
      "It contains 14134 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 18362 rows!\n",
      "It contains 1484 users!\n",
      "It contains 15809 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 18362 rows!\n",
      "It contains 1484 users!\n",
      "It contains 15809 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 24499 rows!\n",
      "It contains 1933 users!\n",
      "It contains 20278 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 24499 rows!\n",
      "It contains 1933 users!\n",
      "It contains 20278 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 14755 rows!\n",
      "It contains 1607 users!\n",
      "It contains 10900 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 14755 rows!\n",
      "It contains 1607 users!\n",
      "It contains 10900 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 19569 rows!\n",
      "It contains 2098 users!\n",
      "It contains 13422 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 19569 rows!\n",
      "It contains 2098 users!\n",
      "It contains 13422 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 14111 rows!\n",
      "It contains 1489 users!\n",
      "It contains 7947 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 14111 rows!\n",
      "It contains 1489 users!\n",
      "It contains 7947 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 18937 rows!\n",
      "It contains 1965 users!\n",
      "It contains 9503 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 18937 rows!\n",
      "It contains 1965 users!\n",
      "It contains 9503 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 18060 rows!\n",
      "It contains 1475 users!\n",
      "It contains 15482 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 18060 rows!\n",
      "It contains 1475 users!\n",
      "It contains 15482 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 24049 rows!\n",
      "It contains 1940 users!\n",
      "It contains 19828 items!\n",
      "Storing dataframe...\n",
      "The current dataframe contains 24049 rows!\n",
      "It contains 1940 users!\n",
      "It contains 19828 items!\n",
      "\n",
      "The dataframe has been stored!\n",
      "=================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'path1 = EXTRA_BOOKS_DIR + \"cds_8_10.csv\"\\npath2 = EXTRA_BOOKS_DIR + \"cds_10_10.csv\"\\n\\nbooks__cd810 = retrieve_user_data_from_dataframe(cds_5_10__BOOKS, cds_5_10__BOOKS_8_10[\\'user_id\\'], path1)\\nbooks__cd10 = retrieve_user_data_from_dataframe(cds_5_10__BOOKS, cds_5_10__BOOKS_10_10[\\'user_id\\'], path2)\\n\\npath1 = EXTRA_BOOKS_DIR + \"movies_8_10.csv\"\\npath2 = EXTRA_BOOKS_DIR + \"movies_10_10.csv\"\\n\\nbooks__movies810 = retrieve_user_data_from_dataframe(movies_5_10__BOOKS, movies_5_10__BOOKS_8_10[\\'user_id\\'], path1)\\nbooks__movies10 = retrieve_user_data_from_dataframe(movies_5_10__BOOKS, movies_5_10__BOOKS_10_10[\\'user_id\\'], path2)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = EXTRA_BOOKS_DIR + \"cds_8_10.csv\"\n",
    "path2 = EXTRA_BOOKS_DIR + \"cds_10_10.csv\"\n",
    "\n",
    "books__cd810 = retrieve_user_data_from_dataframe(cds_5_10__BOOKS, cds_5_10__BOOKS_8_10['user_id'], path1)\n",
    "books__cd10 = retrieve_user_data_from_dataframe(cds_5_10__BOOKS, cds_5_10__BOOKS_10_10['user_id'], path2)\n",
    "\n",
    "path1 = EXTRA_BOOKS_DIR + \"movies_8_10.csv\"\n",
    "path2 = EXTRA_BOOKS_DIR + \"movies_10_10.csv\"\n",
    "\n",
    "books__movies810 = retrieve_user_data_from_dataframe(movies_5_10__BOOKS, movies_5_10__BOOKS_8_10['user_id'], path1)\n",
    "books__movies10 = retrieve_user_data_from_dataframe(movies_5_10__BOOKS, movies_5_10__BOOKS_10_10['user_id'], path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_5_10__CDS = pd.read_csv(CDS35_DIR + \"books5_10.csv\")\n",
    "movies_5_10__CDS = pd.read_csv(CDS35_DIR + \"movies_5_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Cut@8_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 459 users split as follows:\n",
      "- 179 users with 8 reviews\n",
      "- 150 users with 9 reviews\n",
      "- 130 users with 10 reviews\n",
      "=============================\n",
      ">>>>> Cut@8_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 413 users split as follows:\n",
      "- 169 users with 8 reviews\n",
      "- 132 users with 9 reviews\n",
      "- 112 users with 10 reviews\n",
      "=============================\n",
      ">>>>> Cut@10_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 130 users split as follows:\n",
      "- 130 users with 10 reviews\n",
      "=============================\n",
      ">>>>> Cut@10_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 112 users split as follows:\n",
      "- 112 users with 10 reviews\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "books__CDS_grouped = group_data_by_column(books_5_10__CDS, 'user_id', 'item_id')\n",
    "movies__CDS_grouped = group_data_by_column(movies_5_10__CDS, 'user_id', 'item_id')\n",
    "\n",
    "books_5_10__CDS_8_10 = cut_at_x_y(8, 10, books__CDS_grouped, 'no_reviews_user')\n",
    "movies_5_10__CDS_8_10 = cut_at_x_y(8, 10, movies__CDS_grouped, 'no_reviews_user')\n",
    "\n",
    "books_5_10__CDS_10_10 = cut_at_x_y(10, 10, books__CDS_grouped, 'no_reviews_user')\n",
    "movies_5_10__CDS_10_10 = cut_at_x_y(10, 10, movies__CDS_grouped, 'no_reviews_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataframe contains 4082 rows!\n",
      "It contains 459 users!\n",
      "It contains 3926 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 1300 rows!\n",
      "It contains 130 users!\n",
      "It contains 1286 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 3660 rows!\n",
      "It contains 413 users!\n",
      "It contains 2891 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 1120 rows!\n",
      "It contains 112 users!\n",
      "It contains 1020 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "path1 = EXTRA_CDS_DIR + \"books_8_10.csv\"\n",
    "path2 = EXTRA_CDS_DIR + \"books_10_10.csv\"\n",
    "\n",
    "cds__books810 = retrieve_user_data_from_dataframe(books_5_10__CDS, books_5_10__CDS_8_10['user_id'], path1)\n",
    "cds__books10 = retrieve_user_data_from_dataframe(books_5_10__CDS, books_5_10__CDS_10_10['user_id'], path2)\n",
    "\n",
    "path1 = EXTRA_CDS_DIR + \"movies_8_10.csv\"\n",
    "path2 = EXTRA_CDS_DIR + \"movies_10_10.csv\"\n",
    "\n",
    "cds__movies810 = retrieve_user_data_from_dataframe(movies_5_10__CDS, movies_5_10__CDS_8_10['user_id'], path1)\n",
    "cds__movies10 = retrieve_user_data_from_dataframe(movies_5_10__CDS, movies_5_10__CDS_10_10['user_id'], path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_5_10__MOVIES = pd.read_csv(MOVIES35_DIR + \"books5_10.csv\")\n",
    "cds_5_10__MOVIES = pd.read_csv(MOVIES35_DIR + \"cds_5_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Cut@8_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 461 users split as follows:\n",
      "- 192 users with 8 reviews\n",
      "- 144 users with 9 reviews\n",
      "- 125 users with 10 reviews\n",
      "=============================\n",
      ">>>>> Cut@8_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 371 users split as follows:\n",
      "- 176 users with 8 reviews\n",
      "- 109 users with 9 reviews\n",
      "- 86 users with 10 reviews\n",
      "=============================\n",
      ">>>>> Cut@10_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 125 users split as follows:\n",
      "- 125 users with 10 reviews\n",
      "=============================\n",
      ">>>>> Cut@10_10 Scenario <<<<<\n",
      "=============================\n",
      "We have a total of 86 users split as follows:\n",
      "- 86 users with 10 reviews\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "books__MOVIES_grouped = group_data_by_column(books_5_10__MOVIES, 'user_id', 'item_id')\n",
    "movies__MOVIES_grouped = group_data_by_column(cds_5_10__MOVIES, 'user_id', 'item_id')\n",
    "\n",
    "books_5_10__MOVIES_8_10 = cut_at_x_y(8, 10, books__MOVIES_grouped, 'no_reviews_user')\n",
    "cds_5_10__MOVIES_8_10 = cut_at_x_y(8, 10, movies__MOVIES_grouped, 'no_reviews_user')\n",
    "\n",
    "books_5_10__MOVIES_10_10 = cut_at_x_y(10, 10, books__MOVIES_grouped, 'no_reviews_user')\n",
    "cds_5_10__MOVIES_10_10 = cut_at_x_y(10, 10, movies__MOVIES_grouped, 'no_reviews_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataframe contains 4082 rows!\n",
      "It contains 461 users!\n",
      "It contains 3897 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 1250 rows!\n",
      "It contains 125 users!\n",
      "It contains 1228 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 3249 rows!\n",
      "It contains 371 users!\n",
      "It contains 2971 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 860 rows!\n",
      "It contains 86 users!\n",
      "It contains 836 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "path1 = EXTRA_MOVIES_DIR + \"books_8_10.csv\"\n",
    "path2 = EXTRA_MOVIES_DIR + \"books_10_10.csv\"\n",
    "\n",
    "movies__books810 = retrieve_user_data_from_dataframe(books_5_10__MOVIES, books_5_10__MOVIES_8_10['user_id'], path1)\n",
    "movies__books10 = retrieve_user_data_from_dataframe(books_5_10__MOVIES, books_5_10__MOVIES_10_10['user_id'], path2)\n",
    "\n",
    "path1 = EXTRA_MOVIES_DIR + \"cds_8_10.csv\"\n",
    "path2 = EXTRA_MOVIES_DIR + \"cds_10_10.csv\"\n",
    "\n",
    "movies__cds810 = retrieve_user_data_from_dataframe(cds_5_10__MOVIES, cds_5_10__MOVIES_8_10['user_id'], path1)\n",
    "movies__cds10 = retrieve_user_data_from_dataframe(cds_5_10__MOVIES, cds_5_10__MOVIES_10_10['user_id'], path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books DFs len:\n",
      "- books_3_5__1 3397 || - books_3_5__2 3030\n",
      "CDs DFs len:\n",
      "- cds_3_5__1 4958 || - cds_3_5__3 4853\n",
      "Movies DFs len:\n",
      "- movies_3_5__1 4815 || - movies_3_5__3 4794\n"
     ]
    }
   ],
   "source": [
    "books_3_5__1 = pd.read_csv(BOOKS35_DIR + \"books_3_5__1.csv\")\n",
    "books_3_5__2 = pd.read_csv(BOOKS35_DIR + \"books_3_5__2.csv\")\n",
    "print(f\"Books DFs len:\\n\"\n",
    "      f\"- books_3_5__1 {len(books_3_5__1)} || \"\n",
    "      f\"- books_3_5__2 {len(books_3_5__2)}\"\n",
    "      )\n",
    "\n",
    "cds_3_5__1 = pd.read_csv(CDS35_DIR + \"cds_3_5__1.csv\")\n",
    "cds_3_5__3 = pd.read_csv(CDS35_DIR + \"cds_3_5__3.csv\")\n",
    "print(f\"CDs DFs len:\\n\"\n",
    "      f\"- cds_3_5__1 {len(cds_3_5__1)} || \"\n",
    "      f\"- cds_3_5__3 {len(cds_3_5__3)}\"\n",
    "      )\n",
    "\n",
    "movies_3_5__1 = pd.read_csv(MOVIES35_DIR + \"movies_3_5__1.csv\")\n",
    "movies_3_5__3 = pd.read_csv(MOVIES35_DIR + \"movies_3_5__3.csv\")\n",
    "print(f\"Movies DFs len:\\n\"\n",
    "      f\"- movies_3_5__1 {len(movies_3_5__1)} || \"\n",
    "      f\"- movies_3_5__3 {len(movies_3_5__3)}\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataframe contains 1088 rows!\n",
      "It contains 262 users!\n",
      "It contains 1061 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 306 rows!\n",
      "It contains 74 users!\n",
      "It contains 302 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 1033 rows!\n",
      "It contains 246 users!\n",
      "It contains 1005 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 313 rows!\n",
      "It contains 75 users!\n",
      "It contains 309 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "path1 = EXTRA_BOOKS_DIR + \"books_3_5__4.csv\"  # 8_10 cds\n",
    "path2 = EXTRA_BOOKS_DIR + \"books_3_5__5.csv\"  # 10_10 cds \n",
    "\n",
    "books_3_5__4 = retrieve_user_data_from_dataframe(books_3_5__1, books__cd810['user_id'], path1)\n",
    "books_3_5__5 = retrieve_user_data_from_dataframe(books_3_5__1, books__cd10['user_id'], path2)\n",
    "\n",
    "path1 = EXTRA_BOOKS_DIR + \"books_3_5__6.csv\"  # 8_10 movies\n",
    "path2 = EXTRA_BOOKS_DIR + \"books_3_5__7.csv\"  # 10_10 movies\n",
    "\n",
    "books_3_5__6 = retrieve_user_data_from_dataframe(books_3_5__2, books__movies810['user_id'], path1)\n",
    "books_3_5__7 = retrieve_user_data_from_dataframe(books_3_5__2, books__movies10['user_id'], path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataframe contains 1846 rows!\n",
      "It contains 459 users!\n",
      "It contains 1733 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 528 rows!\n",
      "It contains 130 users!\n",
      "It contains 521 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 1643 rows!\n",
      "It contains 413 users!\n",
      "It contains 1558 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 455 rows!\n",
      "It contains 112 users!\n",
      "It contains 449 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "path1 = EXTRA_CDS_DIR + \"cds_3_5__5.csv\"  # 8_10 books\n",
    "path2 = EXTRA_CDS_DIR + \"cds_3_5__6.csv\"  # 10_10 books \n",
    "\n",
    "cds_3_5__5 = retrieve_user_data_from_dataframe(cds_3_5__1, cds__books810['user_id'], path1)\n",
    "cds_3_5__6 = retrieve_user_data_from_dataframe(cds_3_5__1, cds__books10['user_id'], path2)\n",
    "\n",
    "path1 = EXTRA_CDS_DIR + \"cds_3_5__7.csv\"  # 8_10 movies\n",
    "path2 = EXTRA_CDS_DIR + \"cds_3_5__8.csv\"  # 10_10 movies\n",
    "\n",
    "books_3_5__7 = retrieve_user_data_from_dataframe(cds_3_5__3, cds__movies810['user_id'], path1)\n",
    "books_3_5__8 = retrieve_user_data_from_dataframe(cds_3_5__3, cds__movies10['user_id'], path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataframe contains 1808 rows!\n",
      "It contains 461 users!\n",
      "It contains 1569 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 501 rows!\n",
      "It contains 125 users!\n",
      "It contains 473 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 1457 rows!\n",
      "It contains 371 users!\n",
      "It contains 1259 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n",
      "The current dataframe contains 337 rows!\n",
      "It contains 86 users!\n",
      "It contains 323 items!\n",
      "Storing dataframe...\n",
      "The dataframe has been stored!\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "path1 = EXTRA_MOVIES_DIR + \"movies_3_5__5.csv\"  # 8_10 books\n",
    "path2 = EXTRA_MOVIES_DIR + \"movies_3_5__6.csv\"  # 10_10 books \n",
    "\n",
    "movies_3_5__5 = retrieve_user_data_from_dataframe(movies_3_5__1, movies__books810['user_id'], path1)\n",
    "movies_3_5__6 = retrieve_user_data_from_dataframe(movies_3_5__1, movies__books10['user_id'], path2)\n",
    "\n",
    "path1 = EXTRA_MOVIES_DIR + \"movies_3_5__7.csv\"  # 8_10 cds\n",
    "path2 = EXTRA_MOVIES_DIR + \"movies_3_5__8.csv\"  # 10_10 cds\n",
    "\n",
    "movies_3_5__7 = retrieve_user_data_from_dataframe(movies_3_5__3, movies__cds810['user_id'], path1)\n",
    "movies_3_5__8 = retrieve_user_data_from_dataframe(movies_3_5__3, movies__cds10['user_id'], path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "pythonlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
