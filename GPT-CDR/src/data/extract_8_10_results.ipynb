{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_dir_path(curr_working_dir, no_folders_above):\n",
    "    dir_path = curr_working_dir\n",
    "    for i in range(no_folders_above):\n",
    "        dir_path = os.path.dirname(dir_path)\n",
    "    print(f\"Initial directory: {curr_working_dir}\\n\"\n",
    "          f\"Root directory: {dir_path}.\"\n",
    "          )\n",
    "    return dir_path\n",
    "\n",
    "def load_data_pickle_csv(data_to_load):\n",
    "\n",
    "    print(f\"The following files be loaded:\\n\"\n",
    "          f\"- {data_to_load[0]}.pkl\\n\"\n",
    "          f\"- {data_to_load[1]}.csv\\n\"\n",
    "          f\"===================\\nLoading datasets..\"\n",
    "          )\n",
    "    \n",
    "    results_df = pd.read_pickle(data_to_load[0] + \".pkl\")\n",
    "    base_domain_df = pd.read_csv(data_to_load[1] + \".csv\")\n",
    "\n",
    "    print(f\"- No. Unique Users in Target Domain: {len(base_domain_df['user_id'].unique())}\\n\"\n",
    "          f\"Datasets loaded!\\n===================\")\n",
    "\n",
    "    return results_df, base_domain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_root_dir_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m COLUMNS_TYPES \u001b[38;5;241m=\u001b[39m  {\n\u001b[0;32m      2\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m     }\n\u001b[1;32m---> 11\u001b[0m ROOT_DIR \u001b[38;5;241m=\u001b[39m \u001b[43mget_root_dir_path\u001b[49m(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ==================== DATA DIRECTORIES ==================== #\u001b[39;00m\n\u001b[0;32m     14\u001b[0m EXTRA_DATA_DIR \u001b[38;5;241m=\u001b[39m ROOT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/processed/extra_cut/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_root_dir_path' is not defined"
     ]
    }
   ],
   "source": [
    "COLUMNS_TYPES =  {\n",
    "        'user_id': 'string',\n",
    "        'item_id': 'string',\n",
    "        'rating': 'int',\n",
    "        'timestamp': 'string',\n",
    "        'title': 'string',\n",
    "        'brand': 'string',\n",
    "        'category': 'string'\n",
    "    }\n",
    "\n",
    "ROOT_DIR = get_root_dir_path(os.getcwd(), 2)\n",
    "\n",
    "# ==================== DATA DIRECTORIES ==================== #\n",
    "EXTRA_DATA_DIR = ROOT_DIR + '/data/processed/extra_cut/'\n",
    "\n",
    "EXTRA_BOOKS_DIR = EXTRA_DATA_DIR + '/Books/'\n",
    "EXTRA_CDS_DIR = EXTRA_DATA_DIR + '/CDs/'\n",
    "EXTRA_MOVIES_DIR = EXTRA_DATA_DIR + '/Movies/'\n",
    "EXTRA_TEMP_DIR = EXTRA_DATA_DIR + '/Temp/'\n",
    "\n",
    "# ==================== PREDICTION_5_10 DIRECTORIES ==================== #\n",
    "PREDICTIONS_DIR = ROOT_DIR + '/models/predictions/'\n",
    "\n",
    "BOOKS35_CDS510_DIR = PREDICTIONS_DIR + '/books35_cds510/'\n",
    "BOOKS35_MOVIES510_DIR = PREDICTIONS_DIR + '/books35_movies510/'\n",
    "\n",
    "CDS35_BOOKS510_DIR = PREDICTIONS_DIR + '/cds35_books510/'\n",
    "CDS35_MOVIES510_DIR = PREDICTIONS_DIR + '/cds35_movies510/'\n",
    "\n",
    "MOVIES35_BOOKS510_DIR = PREDICTIONS_DIR + '/movies35_books510/'\n",
    "MOVIES35_CDS510_DIR = PREDICTIONS_DIR + '/movies35_cds510/'\n",
    "\n",
    "# ==================== PREDICTION_8_10 DIRECTORIES ==================== #\n",
    "PREDICTIONS_8_10_DIR = ROOT_DIR + '/models/predictions/cut_8_10'\n",
    "\n",
    "BOOKS35_CDS810_DIR = PREDICTIONS_8_10_DIR + '/books35_cds810/'\n",
    "BOOKS35_MOVIES810_DIR = PREDICTIONS_8_10_DIR + '/books35_movies810/'\n",
    "\n",
    "CDS35_BOOKS810_DIR = PREDICTIONS_8_10_DIR + '/cds35_books810/'\n",
    "CDS35_MOVIES810_DIR = PREDICTIONS_8_10_DIR + '/cds35_movies810/'\n",
    "\n",
    "MOVIES35_BOOKS810_DIR = PREDICTIONS_8_10_DIR + '/movies35_books810/'\n",
    "MOVIES35_CDS810_DIR = PREDICTIONS_8_10_DIR + '/movies35_cds810/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_DICT = {\n",
    "\n",
    "    \"books35_cds810_0s\": [BOOKS35_CDS510_DIR + \"books35_cds510_GPT_0s\", EXTRA_BOOKS_DIR + \"cds_8_10\"], \n",
    "    \"books35_cds810_1s\": [BOOKS35_CDS510_DIR + \"books35_cds510_GPT_1s\", EXTRA_BOOKS_DIR + \"cds_8_10\"], \n",
    "\n",
    "    \"books35_movies810_0s\": [BOOKS35_MOVIES510_DIR + \"books35_movies510_GPT_0s\", EXTRA_BOOKS_DIR + \"movies_8_10\"], \n",
    "    \"books35_movies810_1s\": [BOOKS35_MOVIES510_DIR + \"books35_movies510_GPT_1s\", EXTRA_BOOKS_DIR + \"movies_8_10\"], \n",
    "\n",
    "    \"cds35_books810_0s\": [CDS35_BOOKS510_DIR + \"cds35_books510_GPT_0s\", EXTRA_CDS_DIR + \"books_8_10\"], \n",
    "    \"cds35_books810_1s\": [CDS35_BOOKS510_DIR + \"cds35_books510_GPT_1s\", EXTRA_CDS_DIR + \"books_8_10\"], \n",
    "\n",
    "    \"cds35_movies810_0s\": [CDS35_MOVIES510_DIR + \"cds35_movies510_GPT_0s\", EXTRA_CDS_DIR + \"movies_8_10\"], \n",
    "    \"cds35_movies810_1s\": [CDS35_MOVIES510_DIR + \"cds35_movies510_GPT_1s\", EXTRA_CDS_DIR + \"movies_8_10\"], \n",
    "\n",
    "    \"movies35_books810_0s\": [MOVIES35_BOOKS510_DIR + \"movies35_books510_GPT_0s\", EXTRA_MOVIES_DIR + \"books_8_10\"], \n",
    "    \"movies35_books810_1s\": [MOVIES35_BOOKS510_DIR + \"movies35_books510_GPT_1s\", EXTRA_MOVIES_DIR + \"books_8_10\"],\n",
    "\n",
    "    \"movies35_cds810_0s\": [MOVIES35_CDS510_DIR + \"movies35_cds510_GPT_0s\", EXTRA_MOVIES_DIR + \"cds_8_10\"], \n",
    "    \"movies35_cds810_1s\": [MOVIES35_CDS510_DIR + \"movies35_cds510_GPT_1s\", EXTRA_MOVIES_DIR + \"cds_8_10\"],  \n",
    "\n",
    "}\n",
    "\n",
    "all_scenario = ['books35_cds810_0s', 'books35_cds810_1s',           # 0,1\n",
    "                'books35_movies810_0s', 'books35_movies810_1s',     # 2,3\n",
    "                'cds35_books810_0s', 'cds35_books810_1s',           # 4,5\n",
    "                'cds35_movies810_0s', 'cds35_movies810_1s',         # 6,7\n",
    "                'movies35_books810_0s', 'movies35_books810_1s',     # 8,9\n",
    "                'movies35_cds810_0s', 'movies35_cds810_1s'          # 10,11      \n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_8_10_results(scenario_to_use, path_to_store_pickle):\n",
    "\n",
    "    # Path of Scenario's Data \n",
    "    scenario_datasets = PICKLE_DICT[scenario_to_use]\n",
    "\n",
    "    # Load Scenario's Data \n",
    "    res_df, target_dom_df = load_data_pickle_csv(scenario_datasets)\n",
    "\n",
    "    # Extract unique users ids from target domain data\n",
    "    target_dom_unique_users = target_dom_df['user_id'].unique()\n",
    "    \n",
    "    # Extract results of the extracted unique users\n",
    "    tmp_df = res_df[res_df['UserId'].isin(target_dom_unique_users)]\n",
    "\n",
    "    # Store computed dataframe\n",
    "    tmp_df.to_pickle(path_to_store_pickle)\n",
    "    print(f\"{scenario_to_use} results have been stored!\\n=======================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in all_scenario:\n",
    "\n",
    "    if scenario == \"books35_cds810_0s\" or scenario == \"books35_cds810_1s\":\n",
    "        results_path = BOOKS35_CDS810_DIR + scenario + \".pkl\"\n",
    "    elif scenario == \"books35_movies810_0s\" or scenario == \"books35_movies810_1s\":\n",
    "        results_path = BOOKS35_MOVIES810_DIR + scenario + \".pkl\"\n",
    "    \n",
    "    if scenario == \"cds35_books810_0s\" or scenario == \"cds35_books810_1s\":\n",
    "        results_path = CDS35_BOOKS810_DIR + scenario + \".pkl\"\n",
    "    elif scenario == \"cds35_movies810_0s\" or scenario == \"cds35_movies810_1s\":\n",
    "        results_path = CDS35_MOVIES810_DIR + scenario + \".pkl\"\n",
    "\n",
    "    if scenario == \"movies35_books810_0s\" or scenario == \"movies35_books810_1s\":\n",
    "        results_path = MOVIES35_BOOKS810_DIR + scenario + \".pkl\"\n",
    "    elif scenario == \"movies35_cds810_0s\" or scenario == \"movies35_cds810_1s\":\n",
    "        results_path = MOVIES35_CDS810_DIR + scenario + \".pkl\"\n",
    "    \n",
    "    extract_8_10_results(scenario, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "pythonlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
