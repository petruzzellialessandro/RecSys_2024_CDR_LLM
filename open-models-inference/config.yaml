model_dir: 
dataset_path: conf_to_test_mistral
torch_dtype: bf16
generation_parameters:
  max_new_tokens: 256

input_format: "raw"
input_format_parameters:
  text_field: "input"

batch_size: 8
padding_side: "left"
model_name_high:  mistral-chat-lora
output_dir: res_mistral
dataset_setting: zero_shot

pretrained_parameters:
  torch_dtype: bf16